{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udcc4 Curriculum Vitae","text":"<p>A Doctor of Artificial Intelligence, specialising in object detection within the contexts of data scarcity and energy efficiency, currently researching at Kingston University. With extensive experience in AI, VR, AR, and game development across multiple platforms including PC, console, and mobile, I have worked with a range of cutting-edge technologies to design and develop innovative solutions. My expertise spans across Unity, Unreal Engine, and other game engines, with a strong foundation in AI methodologies and optimisation techniques. Passionate about pushing the boundaries of intelligent systems, I seek to apply my knowledge to complex challenges in both academia and industry.</p>"},{"location":"#skills","title":"\ud83d\ude80 Skills","text":""},{"location":"#devops-systems","title":"\ud83d\udd39 DevOps &amp; Systems","text":"<ul> <li>Experienced in Docker, containerizing AI models based on <code>PyTorch</code> and <code>TensorFlow/Keras</code>, resolving complex dependency and driver issues.  </li> <li>Proficient in Linux (<code>Ubuntu</code>, <code>Arch Linux</code>, <code>Void Linux</code>), managing system installations, deployment, and containerization of machine learning applications.  </li> <li>Skilled in developing asynchronous backend systems using <code>FastAPI</code>, <code>Celery</code>, and <code>Redis</code> for efficient task processing and scalability.  </li> </ul>"},{"location":"#artificial-intelligence-data-science","title":"\ud83d\udd39 Artificial Intelligence &amp; Data Science","text":"<ul> <li>Strong background in data science, developing AI methodologies with <code>PyTorch</code>, <code>TensorFlow/Keras</code>, <code>NumPy</code>, <code>Pandas</code>, <code>ImageAI</code>, and <code>Streamlit</code>.  </li> <li>Hands-on experience in computer vision, implementing deep learning models and optimizing inference pipelines for real-time applications.  </li> </ul>"},{"location":"#programming-software-development","title":"\ud83d\udd39 Programming &amp; Software Development","text":"<ul> <li>Expertise in C/C++, working on PS4 game development, <code>OpenGL</code> and <code>Vulkan</code> graphics programming, and game engines like <code>Unity</code>, <code>Unreal Engine 4</code>, <code>cocos2d-x</code>, and <code>GFC (SDL-based)</code>.  </li> <li>Proficient in C#, specializing in Unity game and tools development for various projects.  </li> <li>Strong knowledge of Python, developing applications for Linux platforms, <code>Raspberry Pi</code> GPIO interactions, <code>KIWI</code>, <code>Neural Networks</code>, <code>scikit-learn</code>, and experimental DNA analysis projects.  </li> <li>Experience with web development, using <code>JavaScript</code>, <code>HTML</code>, <code>CSS</code>, and <code>PHP</code> for database interactions and <code>AJAX</code> implementations.  </li> </ul>"},{"location":"#education","title":"\ud83c\udf93 Education","text":"<ul> <li> <p>Ph.D. in Artificial Intelligence Kingston University (2021 \u2013 2024)  </p> </li> <li> <p>M.Sc. in Games Development (Games Programming) Kingston University (2019 \u2013 2020)  </p> </li> <li> <p>B.Sc. with Honours in Computer Science (Games Programming) Kingston University (2015 \u2013 2019)  </p> </li> </ul>"},{"location":"#publications","title":"\ud83d\udcda Publications","text":"<ul> <li> <p>Enhancing 3D Object Detection in Autonomous Vehicles Based on Synthetic Virtual Environment Analysis V. Li, I. Siniosoglou, T. Karamitsou, A. Lytos, I.D. Moscholios, S.K. Goudos, ... Image and Vision Computing, 154, 105385 Year: 2025</p> </li> <li> <p>Evaluating the Energy Efficiency of Few-Shot Learning for Object Detection in Industrial Settings G. Tsoumplekas, V. Li, I. Siniosoglou, V. Argyriou, S.K. Goudos, ... arXiv Preprint arXiv:2403.06631 Year: 2024</p> </li> <li> <p>Toward Green and Human-Like Artificial Intelligence: A Complete Survey on Contemporary Few-Shot Learning Approaches G. Tsoumplekas, V. Li, V. Argyriou, A. Lytos, E. Fountoukidis, S.K. Goudos, ... arXiv Preprint arXiv:2402.03017 Year: 2024</p> </li> <li> <p>A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection V. Li, G. Tsoumplekas, I. Siniosoglou, V. Argyriou, A. Lytos, E. Fountoukidis, ... 2024 IEEE 14th International Symposium on Industrial Embedded Systems (SIES) Year: 2024</p> </li> <li> <p>Super Resolution for Augmented Reality Applications V. Li, G. Amponis, J.C. Nebel, V. Argyriou, T. Lagkas, S. Ouzounidis, ... IEEE INFOCOM 2022 \u2013 IEEE Conference on Computer Communications Workshops Year: 2022</p> </li> <li> <p>Object Recognition for Augmented Reality Applications V. Li, G. Amponis, J.C. Nebel, V. Argyriou, T. Lagkas, P. Sarigiannidis Azerbaijan Journal of High Performance Computing, 4(1), 15-28 Year: 2022</p> </li> <li> <p>Evaluation of Environmental Conditions on Object Detection Using Oriented Bounding Boxes for AR Applications V. Li, B. Villarini, J.C. Nebel, T. Lagkas, P. Sarigiannidis, V. Argyriou 19th International Conference on Distributed Computing in Smart Systems Year: 2023</p> </li> <li> <p>A Modular Deep Learning Framework for Scene Understanding in Augmented Reality Applications V. Li, B. Villarini, J.C. Nebel, V. Argyriou IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology Year: 2023</p> </li> <li> <p>Growth-Based 3D Modelling Using Stem-Voxels Encoded in Digital-DNA Structures T. Raymond, V. Li, V. Argyriou SIGGRAPH Asia 2020 Posters, 1-2 Year: 2020</p> </li> </ul>"},{"location":"#work-experience","title":"\ud83e\uddd1\u200d\ud83d\udcbc Work Experience","text":"<ul> <li> <p>Researcher, Kingston University (2021 \u2013 Present)   Engaged in advanced research in the field of Artificial Intelligence, focusing on object recognition, virtual reality applications, and few-shot learning methodologies.</p> </li> <li> <p>Teaching Assistant, Kingston University (2020 \u2013 2021)   Assisted in teaching and grading assignments for undergraduate and graduate students, particularly in the domains of computer science and artificial intelligence.</p> </li> <li> <p>Creative Programmer, Kingston University (2020)   Developed innovative software solutions and interactive experiences for academic projects, with a focus on AI applications and game development.</p> </li> <li> <p>Teaching Assistant, Kingston University (2018 \u2013 2019)   Provided support for various computer science courses, helping students with course material, assignments, and practical coding exercises.</p> </li> </ul>"},{"location":"#projects-involvement","title":"\ud83d\ude80 Projects Involvement","text":"<ul> <li> <p>RAIDO Kingston University (2023 \u2013 2026)   Reliable AI and Data Optimization (RAIDO) - an ongoing EU Commission-funded international project focusing on developing innovative solutions for AI model reliability and data optimization in industrial and research applications.</p> </li> <li> <p>TALON Kingston University (2022 \u2013 2025)   Autonomous and Self-organized Artificial Intelligent Orchestrator for a Greener Industry 4.0. This EU Commission-funded international project leverages AI to optimize industrial processes and reduce environmental impact.</p> </li> <li> <p>Leonardo Kingston University (2020 \u2013 2022)   An object detection project for Leonardo, a private company focused on advanced AI techniques for recognizing and analyzing various objects in complex environments, particularly in industrial and aerospace sectors.</p> </li> </ul>"},{"location":"#additional-experience-projects","title":"\ud83c\udfae\u2728 Additional Experience &amp; Projects","text":"<ul> <li> <p>Game Jams</p> <ul> <li>2020 Ludum Dare 47: Loop</li> <li>2020 Ludum Dare 46: Abducted</li> <li>2019 inKUbator Game Jam: Winner \u2013 Nobel Knight</li> <li>2019 Bental's Centre Game Jam: Red Boy</li> <li>2018 inKUbator Game Jam: Winner \u2013 Cell Resistence</li> <li>2016 inKUbator Game Jam: Save the Village</li> </ul> </li> <li> <p>Side Projects</p> <ul> <li>Peasants Engine \u2013 An attempt to implement a single-header legacy game engine.</li> <li>Noname FPS \u2013 A collaboration project with Tyler Pope developing an FPS using Unreal Engine 4.23.</li> </ul> </li> </ul>"},{"location":"#keywords","title":"Keywords","text":"<ul> <li>Unity3D, Unreal Engine, cocos2d-x, KIWI, WebGL, Android, PS4, PC, Hololens AR, Oculus Rift VR, HTC Vive VR</li> <li>Visual Studio, Visual Studio Code, C/C++, C#, Python, JavaScript, HTML, CSS, Forex Trading MQL4/5, OOP, ECS</li> <li>Component-based Design, Design Patterns, Engine Architecture, GFC, SDL, OpenGL, Vulkan, Unity Barracuda</li> <li>AI Object Recognition, Perforce, Git</li> </ul>"},{"location":"manual/","title":"\ud83d\udcd6 Manual","text":""},{"location":"manual/#introduction","title":"Introduction","text":"<p>This is a manual that contains useful code snippets, including personal and internet code. I am trying to keep the repository somewhat structured, however, there is no single rigid structure by design, but rather a chaotic collection of things that I think might be helpful. Enjoy figuring this out.</p>"},{"location":"manual/#how-to-create-bootable-installation-media","title":"How to Create Bootable Installation Media","text":"<p>First, download the installation ISO file from the official website [1, 2, 3]. Then, write (or \"flash\") the ISO file onto a USB flash drive [1] using a tool like Rufus [1] if you are on Windows. If you are using Linux or macOS, you can flash the ISO file using the <code>dd</code> command in the terminal. Be very careful with <code>dd</code>, as it can overwrite any drive:</p> <pre><code>sudo dd if=/path/to/your.iso of=/dev/sdX bs=4M status=progress oflag=sync\n</code></pre> <ul> <li>Replace <code>/path/to/your.iso</code> with the path to the ISO file you downloaded.</li> <li>Replace <code>/dev/sdX</code> with your USB device (e.g., <code>/dev/sdb</code>). Important: Do not write to a partition like <code>/dev/sdb1</code>, only to the whole device <code>/dev/sdb</code>.</li> </ul> <p>Make sure your USB flash drive is large enough; for example, if the ISO file is 1.2 GB, it is sensible to use a USB drive with at least 4 GB of storage. Once the ISO is written, plug the USB drive into the target computer. To boot from the USB, you may need to press a special key during startup \u2014 check the motherboard manual to find out which key to use (often F12, ESC, or F10).</p>"},{"location":"manual/#how-to-install-arch","title":"How to Install Arch","text":"<p>Once the installation has started and the system has loaded, refer to the instructions outlined in section 1. You should see a <code>zsh</code> shell, where you are logged in as <code>root@archiso</code>. From this point onwards, the next step, according to the official documentation [1], is to set the keyboard layout:</p> <pre><code>loadkeys uk\n</code></pre> <p>In situations, where the layout name is unknown, the <code>localectl list-keymaps</code> command would list all available layouts that could be viewed using regular arrow keys in a terminal.</p> <pre><code>localectl list-keymaps\n</code></pre> <p>Based on the quick Google search, good UK fonts are <code>ter-v32b</code>, <code>Uni2-Terminus16</code>, <code>Lat2-Terminus32x16</code>, and <code>Lat2-Terminus16</code>. The <code>ter-v20b</code> font is a smaller variant which seems to be a good fit for my monitor size, i.e. 24\u2033 at 1080p. Notably, these fonts won't be available in the installed system\u2014perhaps because I\u2019m missing some crucial steps that copy the fonts over to the installed OS.</p> <p><pre><code>setfont ter-v20b\n</code></pre> Similar to the layout name, it possible to preview the fonts using a command to list all files in the fonts folder. The <code>--color=always</code> and <code>-R</code> parameters are to preserve the colour in the output.</p> <pre><code>ls -lash --color=always /usr/share/kbd/consolefonts/ | less -R\n</code></pre> <p>Verify the boot mode [1]. The output could be either <code>64</code> or <code>32</code>, in my case it was <code>64</code>. There could be situations where the file is missing. In such situations, it means the system was booted in BIOS mode.</p> <pre><code>cat /sys/firmware/efi/fw_platform_size\n</code></pre> <p>Verify the networking status by first checking if the network interface is up. Importantly, the <code>UP</code> flag appears inside angle brackets. In my case, it was easy to mistake this for <code>state DOWN</code>, especially since the latter was highlighted in red due to the <code>--color</code> parameter.</p> <pre><code>ip --color link\n</code></pre> <p>If the connection is down and the only way is to use WiFi, then use <code>iwctl</code>. From an extensive search on the internet, this command seems to be the easiest and most recommended way of connecting to Wi-Fi.</p> <pre><code>iwtcl\n</code></pre> <p>There could be a special situation where we would be bound to notorious <code>eduroam</code>. Then we have to create a configuration file and let <code>iwctl</code> to pick it up. An example file is stored at <code>project/archlinux/var/lib/iwd/eduroam.8021x</code> which is a configuration for the <code>eduroam</code> network using login and password. Required by <code>iwctl</code>. There is <code>project/archlinux/var/lib/iwd/eduroam.8021x</code> which is a configuration to let built-in DHCP daemon resolve an IP address for the host. In case if the installed OS plans to use <code>iwctl</code> to connect to <code>eduroam</code> later then install <code>iwd</code> and <code>dhcpdc</code> and then <code>systemctl enable iwd</code> and <code>systemctl enable dhcpdc</code> to run the daemons on the system start up. Then inside the <code>iwctl</code> tool:</p> <pre><code>device list\nstation wlan0 scan\nstation wlan0 get-networks\nstation wlan connect [network_name]\nexit\n</code></pre> <p>Check the internet connection:</p> <pre><code>ping archlinux.org\n</code></pre> <p>Manually check and sync the time and date:</p> <pre><code>timedatectl\n</code></pre> <p>List the available storage devices and their locations:</p> <pre><code>lsblk\n</code></pre> <p>In my case, it listed <code>/dev/nvme0n1</code>. Then, I used the <code>fdisk</code> utility to partition the drive:</p> <pre><code>fdisk /dev/nvme0n1\n</code></pre> <p>Next, you are presented with a somewhat interactive text-based interface (TUI), although, in my opinion, it uses a rather cryptic method of operation. For example, it uses a single letter <code>p</code> to list information about the current partitioning, if any. I would personally prefer to type out full commands, but we have to work with what is provided. At this stage, I created an <code>EFI</code>, a <code>swap</code>, and a <code>Linux filesystem</code> partition. This part is not detailed in the official guide, as partitioning schemes are use-case specific. Fortunately, the author in [1] offers some helpful hints.</p> <pre><code>g # Create GPT.\nENTER\nn # Create new partition.\nENTER\nENTER\nENTER\n+512M\nENTER\nt # Change type.\nENTER\nENTER\n1 # To EFI.\nENTER\nn # Create new partition.\nENTER\nENTER\nENTER\n+32G\nENTER\nt # Change type.\nENTER\nENTER\nswap # To swap.\nENTER\nn # Create new partition.\nENTER\nENTER\nENTER\nENTER\np # View the results so far.\nENTER\nw # Write it.\nENTER\n</code></pre> <p>Format the partitions:</p> <pre><code>mkfs.fat -F 32 /dev/nvme0n1p1\nmkswap /dev/nvme0n1p2\nmkfs.ext4 /dev/nvme0n1p3\n</code></pre> <p>Now, mount the file systems. Be careful with the order here: first mount the main filesystem, and then mount the EFI system partition. If you mount them in the wrong order, the EFI mount point may overwrite itself and fail to appear correctly in <code>/etc/fstab</code> later.</p> <pre><code>mount /dev/nvme0n1p3 /mnt\nmount --mkdir /dev/nvme0n1p1 /mnt/boot\nswapon /dev/nvme0n1p2\n</code></pre> <p>Install the essential packages: <code>base</code>, <code>linux</code>, and <code>linux-firmware</code>. These form the minimum needed to have a functional operating system.</p> <p>The <code>efibootmgr</code> and <code>grub</code> packages are required to pass control from the UEFI firmware to the Linux kernel. There are other bootloaders available, but I am most familiar with these. Without these packages, the rest of the installation would not work.</p> <p>It is possible to install <code>amd-ucode</code> after booting into Arch Linux, but it is best to install it during setup so that it can be loaded early through the bootloader for full effect. If you are using an Intel CPU, use <code>intel-ucode</code> instead.</p> <p>The <code>networkmanager</code> package is needed to connect to the internet after the installation, in order to complete the post-installation setup. For most users, NetworkManager is the better choice due to its ease of use, GUI support, and good compatibility with desktop environments. Although, iwd is lighter and faster, but it is better suited for minimal or embedded setups.</p> <pre><code>pacstrap -K /mnt base linux linux-firmware efibootmgr grub amd-ucode networkmanager\n</code></pre> <p>Generate an <code>fstab</code> file.</p> <pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab\n</code></pre> <p>Verify <code>/etc/fstab</code>.</p> <pre><code>vim /mnt/etc/fstab\n</code></pre> <p>Change root into the new system.</p> <pre><code>arch-chroot /mnt\n</code></pre> <p>Set the time zone.</p> <pre><code>ln -sf /usr/share/zoneinfo/Europe/London /etc/localtime\n</code></pre> <p>Run hwclock to generate <code>/etc/adjtime</code>.</p> <pre><code>hwclock --systohc\n</code></pre> <p>Edit <code>/etc/locale.gen</code> and uncomment <code>en_GB.UTF-8 UTF-8</code> and other needed UTF-8 locales. Then, generate the locales.</p> <pre><code>locale-gen\n</code></pre> <p>Create the <code>/etc/locale.conf</code> file, and set the LANG variable accordingly.</p> <pre><code>LANG=en_GB.UTF-8\n</code></pre> <p>If you set the console keyboard layout, make the changes persistent in <code>/etc/vconsole.conf</code>. Later on, we can also change the font of the console [1].</p> <pre><code>KEYMAP=uk\n</code></pre> <p>Create the <code>/etc/hostname</code> file.</p> <pre><code>Standard-PC\n</code></pre> <p>Set the root password.</p> <pre><code>passwd\n</code></pre> <p>Add user.</p> <pre><code>useradd -mG wheel user\npasswd user\n</code></pre> <p>Deploy grub.</p> <pre><code>grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=GRUB\n</code></pre> <p>Generate the grub configuration (it will include the microcode installed with <code>pacstrap</code> earlier).</p> <pre><code>grub-mkconfig -o /boot/grub/grub.cfg\n</code></pre> <p>Enable NetworkManager before rebooting. This is considered good practice within the community. The main reason is to ensure network connectivity after rebooting, especially in situations where an SSH service is set up and there is no input or output available, such as no keyboard, mouse, or monitor connected to the system.</p> <pre><code>systemctl enable NetworkManager\n</code></pre> <p>Exit from <code>chroot</code>.</p> <pre><code>exit\n</code></pre> <p>Unmount everything to check if the drive is busy.</p> <pre><code>umount -R /mnt\n</code></pre> <p>Reboot the system and unplug the installation media.</p> <p>Note</p> <p>Instead, I prefer to shutdown the PC, unplug the USB drive, and manually boot back.</p> <pre><code>shutdown -h now\n</code></pre>"},{"location":"manual/#how-to-post-install-arch","title":"How to Post Install Arch","text":"<p>After the installation of the barebones Arch Linux [1]. Basic terminal login should be presented to the user. Log in with your user credentials.</p> <p>Once logged in, ensure that the internet connection is working. Refer to the <code>ip --color link</code> command mentioned in [1] to verity the networking status. In situations where there is only Wi-Fi then use <code>nmcli</code>. Otherwise, the wire connection usually picked up automatically.</p> <pre><code>nmcli device wifi list\nnmcli device wifi connect *SSID* password *your_wifi_password*\nnmcli connection show\n</code></pre> <p>Enable and start the time synchronisation service. It requires an active internet connection to synchronise the system clock with online NTP servers.</p> <pre><code>timedatectl set-ntp true\n</code></pre> <p>Configure pacman and mirrors. All was okay for me, so I just skimmed it through and left it as is.</p> <pre><code>cat /etc/pacman.d/mirrorlist | less -R\ncat /etc/pacman.conf | less -R\n</code></pre> <p>Update and upgrade the system.</p> <pre><code>sudo pacman -Syu\n</code></pre> <p>To proceed further, it is paramount to install custom packages to help better manage hardware resources and improve overall UX. The <code>base-devel</code> package group in Arch Linux provides essential development tools like <code>make</code>, <code>gcc</code>, and <code>binutils</code>, which are required to compile software, especially when using the AUR (Arch User Repository) [1]. The <code>openssh</code> package is used to ssh and manage keys. The <code>neovim</code> package is my default editor of choice. The <code>man</code> package to \"read the f-ing manual\" [1]. The <code>git git-lfs</code> packages are there because of VCS [1]. To download files from the internet: <code>curl wget</code>. The <code>xorg xorg-xinit</code> packages are to enable GUI through X Systems as I consider Wayland too early to adapt. The <code>xf86-video-amdgpu</code> package is optional and it was included because the target computer iGPU is AMD-based. The <code>polkit-gnome</code> package is optional. Some software require priviliges and they are capable to self-elevate the priviliges if <code>polkit</code> is available. It comes as a dependency of the <code>polkit-gnome</code> package. The <code>alacritty</code> terminal is the default temrinal emulator of choice. The <code>firefox</code> browser is a compromise between widely available and provided the features I like. The <code>keepassxc</code> software is a password manager tool. To connect to my Google Drive I use <code>rclone</code>. To make colours warmer during late hours I use <code>redshift</code>. The <code>p7zip</code> package is used to extract archives. The <code>pipewire pipewire-alsa pipewire-pulse pipewire-jack wireplumber</code> packages are needed to manage audio. The new audio framework replacing pulse and jack. And, <code>wireplumber</code> is the pipewire session manager. The <code>bluez bluez-utils</code> packages provide <code>bluetoothctl</code>. Finally, we install a bunch of fancy fonts, <code>terminus-font nerd-fonts ttf-terminus-nerd noto-sans noto-fonts-cjk noto-fonts-emoji noto-fonts-extra ttf-font-awesome</code>, at a cost of large storage space, i.e. aproximately 8-9 GB. On a bright side, it should cover almost any character including various emojis.</p> <pre><code>sudo pacman --sync base-devel openssh neovim man git git-lfs curl wget xorg xorg-xinit xf86-video-amdgpu polkit-gnome alacritty firefox keepassxc rclone redshift p7zip pipewire pipewire-alsa pipewire-pulse pipewire-jack wireplumber bluez bluez-utils terminus-font nerd-fonts ttf-terminus-nerd noto-sans noto-fonts-cjk noto-fonts-emoji noto-fonts-extra ttf-font-awesome\n</code></pre> <p>As in [1, 2], to find what package is required to install a command run the following.</p> <pre><code>clear ; sudo pacman -Fy bluetoothctl\n</code></pre> <p>I wanted to keep the barebones Arch Linux installation as minimal as possible, so I moved console font configuration to here as a post-installation step. Append <code>/etc/vconsole.conf</code>. The <code>FONT</code> parameter depends on the <code>terminus-font</code> package, and while optional, it resolved a warning that was raised when building <code>mkinitcpio</code> [1]. This font is used system-wide when booting into the system.</p> <pre><code>FONT=ter-v20b\n</code></pre> <p>After modification, the initial RAM file system needs to be rebuilt. After reboot, the console fonts should change to the one specified in the configuration file.</p> <pre><code>sudo mkinitcpio -p linux\n</code></pre> <p>To enable bluetooth, installed <code>bluez</code>, and <code>bluez-utils</code>. The utilities package should contain <code>bluetoothctl</code> command [1]. Enable and start the service.</p> <pre><code>clear ; sudo systemctl status bluetooth\nclear ; sudo systemctl enable bluetooth\nclear ; sudo systemctl start bluetooth\nclear ; sudo systemctl status bluetooth\n</code></pre> <p>To connect a device via <code>bluetoothctl</code>.</p> <pre><code>bluetoothctl\npower on\nagent on\nscan on\npair &lt;MAC&gt;\nconnect &lt;MAC&gt;\ntrust &lt;MAC&gt;\n</code></pre> <p>The most up-to-date approach to manage audio seems to be <code>pipewire</code> but it comes with its own quirks like <code>rtkit</code> warnings [1]. On a bright side, it seems like it works out-of-the-box.</p> <p>At this point, it might be a good idea to install a GUI like <code>dwm</code>. Refer to the instructions in [1] to install <code>dwm</code>.</p> <p>Since we installed polkit and the agent, let's add it to the <code>.xinitrc</code>. This is optional as it requires polkit and implies that we use WM instead of a DE.</p> <pre><code>exec /usr/lib/polkit-gnome/polkit-gnome-authentication-agent-1 &amp;\n</code></pre> <p>At this point, the customised part of <code>~/.xinitrc</code> should have the following. To find <code>ATITUDE:LONGITUDE</code> for Redshift follow the instructions at [1].</p> <pre><code># my rules\nsetxkbmap gb\nstatus &amp;\nredshift -P -O 2700 -l LATITUDE:LONGITUDE &amp;\nexec /usr/lib/polkit-gnome/polkit-gnome-authentication-agent-1 &amp;\nexec dwm\n</code></pre> <p>And, <code>~/.bashrc</code> should lhave the following.</p> <pre><code>alias ls='LC_COLLATE=C ls --color=auto --group-directories-first --sort=version'\nalias ll='ls -lashF'\n\nPATH=~/.local/bin:$PATH\n\n# By default, Arch would use `vi` as the default editor.\nexport EDITOR=nvim\n</code></pre> <p>There was a situation where the PC used iGPU to calculate graphics but used dGPU to output graphics. In situations where the PC should be forced to use <code>xf86-video-amdgpu</code> modify <code>/etc/X11/xorg.conf.d/xorg.conf</code>. Bare in mind that <code>\"PCI:19:0:0\"</code> is taken from the output of <code>lspci -nnk</code>, where the numbers are represented in hexadecimal format but the <code>BusID</code> is in decimal format. I didn't need to append zeros at the beginning, e.g. <code>PCI:0:19:0</code> is invalid.</p> <pre><code>Section \"Device\"\n    Identifier \"iGPU\"\n    Driver \"amdgpu\"\n    BusID \"PCI:19:0:0\"\nEndSection\n</code></pre> <p>At this point, the installation of Arch Linux should be somewhat usable. Further information on post-installation advices is available at 1.</p>"},{"location":"manual/#how-to-install-ubuntu","title":"How to Install Ubuntu","text":"<p>Once the installation has started and the system has loaded, as mentioned in the section 1. Follow on-screen instructions.</p>"},{"location":"manual/#how-to-post-install-ubuntu","title":"How to Post Install Ubuntu","text":"<p>The post-installation phase involves setting up programs that are useful regardless of the system\u2019s purpose \u2014 whether for computer vision tasks, game development, or general use. The programs listed in this section are valuable in any setup.</p> <p>Note</p> <p>Some packages, like <code>build-essential</code>, may already be installed by default on certain systems, such as Ubuntu 20.04.5.</p> <p>The <code>build-essential</code> package installs important development tools, including a compiler, linker, libraries, and headers used during software compilation. Many third-party programs rely on it, and errors can occur if it is missing. It often comes pre-installed on some distributions.</p> <pre><code>sudo apt install build-essential\n</code></pre> <p>The <code>ubuntu-restricted-extras</code> package installs software not included in the Ubuntu installation ISO due to copyright restrictions. It includes programs such as:</p> <ul> <li><code>ttf-mscorefonts-installer</code></li> <li><code>libavcodec-extra</code></li> <li><code>libavcodec-extra58</code></li> <li><code>libmspack0</code></li> <li><code>libvo-amrwbenc0</code></li> <li><code>unrar</code></li> <li><code>cabextract</code></li> <li><code>libaribb24-0</code></li> </ul> <p>Install it with:</p> <pre><code>sudo apt install ubuntu-restricted-extras\n</code></pre> <p>The <code>gstreamer1.0-libav</code>, <code>gstreamer1.0-plugins-ugly</code>, and <code>gstreamer1.0-vaapi</code> packages provide additional multimedia support, similar to what <code>ubuntu-restricted-extras</code> offers. However, unlike <code>ubuntu-restricted-extras</code>, these packages are available on many Debian-based distributions, not just Ubuntu.</p> <p>Install them with:</p> <pre><code>sudo apt install gstreamer1.0-libav \\\n                 gstreamer1.0-plugins-ugly \\\n                 gstreamer1.0-vaapi\n</code></pre> <p>The <code>fonts-powerline</code> package installs special fonts which make the BASH shell easier on the eyes, particularly when using tools like oh-my-bash.</p> <pre><code>sudo apt install fonts-powerline\n</code></pre> <p>The <code>p7zip-full</code> package installs a utility to archive and unarchive files. This is an important tool to have. </p> <p>Note</p> <p>A small reminder: when extracting files, the <code>-o</code> option in the <code>7z</code> command must not have a space between <code>-o</code> and the output path.</p> <p>Example:</p> <pre><code>7z x \"archive.zip\" -ooutput/path\n</code></pre> <p>Install <code>p7zip-full</code> with:</p> <pre><code>sudo apt install p7zip-full\n</code></pre> <p>The <code>curl</code> and <code>wget</code> packages install utilities that allow downloading files from remote computers via URLs. Typically, <code>wget</code> comes pre-installed with Ubuntu, but <code>curl</code> may not. I prefer to have both available.</p> <pre><code>sudo apt install curl wget\n</code></pre> <p>The <code>ffmpeg</code> package installs a utility for working with media files, such as MPEG-4 videos and MP3 audio. However, I have found it better to install <code>ffmpeg</code> inside a <code>conda</code> environment to keep the system-level environment clean.</p> <pre><code>sudo apt install ffmpeg\n</code></pre> <p>The <code>git</code> package is the most common source code management tool. Although there are other tools like Plastic SCM and Perforce, most teams use <code>git</code>. It is also useful to install <code>git-lfs</code> for handling large files.</p> <pre><code>sudo apt install git git-lfs\n</code></pre> <p>Sometimes, Git Large File Storage (LFS) can cause issues. I usually resolve them with:</p> <pre><code>git lfs install --skip-repo\n</code></pre>"},{"location":"manual/#how-to-troubleshoot-gdm3-on-ubuntu-with-wayland","title":"How to Troubleshoot <code>gdm3</code> on Ubuntu with Wayland","text":"<p>On Ubuntu 24.04, the gdm3 display manager by default runs on Wayland. However, sometimes, e.g. ast driver, doesn't work with Wayland. To switch to Xorg uncomment <code>WaylandEnable=false</code> line by modifying <code>/etc/gdm3/custom.conf</code> configuration file. Save the file and reboot. This is the only working solution I have found so far.</p> <p>I have tried many things, such as reinstalling by removing gdm3. I switched to tty3, using <code>Ctrl+Alt+F3</code> and stopped the display manager service, i.e. gdm3, using commands below. Stopping gdm and display-manager.service act as aliases and, in my opinion, it is better to stop the original service. I have tried both removing then rebooting, as well as, removing without rebooting. Also, I tried with and without stopping the gdm3 service. Unfortunately, it didn't help.</p> <pre><code>sudo systemctl stop gdm3\nsudo apt remove gdm3\nsudo apt install gdm3.\n</code></pre> <p>I have tried reinstalling by purging gdm3. I did the same experiments as with removing. Initially, when I tried to stop the service, purge it, and install it without rebooting the display manager started to work. Happily after, I logged into my user account and all seemed to be working. However, when I have rebooted, the problem came back.</p> <pre><code>sudo systemctl stop gdm3\nsudo apt purging gdm3\nsudo apt install gdm3.\n</code></pre>"},{"location":"manual/#how-to-install-windows","title":"How to Install Windows","text":"<p>Once the installation has started and the system has loaded, as mentioned in the section 1. Follow on-screen instructions.</p>"},{"location":"manual/#how-to-post-install-windows","title":"How to Post Install Windows","text":"<ol> <li> <p>Windows 11     After installation, the B650I AX would prompt with a GIGABYTE Control Center. My advice is to avoid it. The software is heavily under developed. Firstly, I started installing the driver for the chipset, mb_driver_597_chipset_7.01.08.129. Then, LAN driver, mb_driver_654_w11_11.21.0903.2024. Then, Audio driver, mb_driver_612_realtekdch_6.0.9733.1. Then, Video driver for APU, mb_driver_2689_apu5_24.30.18.241224. Then, Bluetooth driver, mb_driver_675_realtek8852_1.1068.2401.1903. Interestingly, it prompted me whether I should re-install it using compatibility settings which I actually did but only once.</p> </li> <li> <p>Windows 10</p> <p>Windows 10 is a major release of Microsoft's Windows NT operating system. It is the direct successor to Windows 8.1, which was released nearly two years earlier. It was released to manufacturing on July 15, 2015, and later to retail on July 29, 2015. Windows 10 was made available for download via MSDN and TechNet, as a free upgrade for retail copies of Windows 8 and Windows 8.1 users via the Microsoft Store, and to Windows 7 users via Windows Update. Windows 10 receives new builds on an ongoing basis, which are available at no additional cost to users, in addition to additional test builds of Windows 10, which are available to Windows Insiders. Devices in enterprise environments can receive these updates at a slower pace, or use long-term support milestones that only receive critical updates, such as security patches, over their ten-year lifespan of extended support. In June 2021, Microsoft announced that support for Windows 10 editions which are not in the Long-Term Servicing Channel (LTSC) will end on October 14, 2025.</p> <ul> <li>To display Russian characters instead of squares.<ol> <li>Open Language settings.</li> <li>Open Administrative language settings.</li> <li>Open Language for non-Unicode programs.</li> <li>Click on the \"Change system locale...\" button.</li> <li>Under Current system locale, select Russian (Russia).<ol> <li>Don't check \"Beta: Use Unicode UTF-8 for worldwide language support\".</li> </ol> </li> <li>Restart the PC.</li> </ol> </li> <li>List of common applications I need.<ul> <li>7-zip</li> <li>miniconda3 (more details here)</li> <li>FastStone Image Viewer</li> <li>Git</li> <li>KeePass</li> <li>Substituted KeePass with KeePassX because it is more modern.</li> <li>VLC</li> <li>WSL (more details here)</li> <li>VirtualBox required Microsoft Redistributable 2019</li> <li>Docker (more details here)</li> </ul> </li> </ul> </li> </ol>"},{"location":"manual/#how-to-bypass-the-networking-requirement-during-the-windows-11-installation","title":"How to Bypass the Networking Requirement during the Windows 11 Installation","text":"<p><code>Shift</code> + <code>F10</code> to open up Windows Command Prompt.</p> <pre><code>oobe\\bypassnro\n</code></pre> <p>The system should reboot and, at the step where it prompts the user to connect to the internet, the <code>I don't have internet</code> button should be appear.</p>"},{"location":"manual/#what-to-install","title":"What to Install","text":"<ol> <li>Timeshift to backup &amp; restore on Linux.</li> <li>Remmina to connect to a remote desktop on Linux. Remote Desktop Connection on Windows.</li> <li>Firefox to access the internet.</li> <li>KeePassXC to manage passwords.</li> <li><code>rclone</code> to use Google Drive to share files.</li> <li><code>mc</code>, <code>nnn</code> to manage files.</li> <li><code>nvim</code>, VS Code to edit text.</li> </ol>"},{"location":"manual/#remote-desktop","title":"Remote Desktop","text":"<p>Remotely accessing desktops is a simple concept, but very cumbursome on practice. There are a lot of paid solutions such as AnyDesk, TeamViewer, ZeroTier, etc. However, ideally, we want a self-hosted solution, so that we could run it indefinitely without heavy reliance on third party developers. There we could consider open source solutions like RustDesk &amp; RustDesk Server software, xrdp, freerdp, etc. Futhermore, we can consider software such as Guacamole. Unfortunately, all of the software has thair strong and not so strong sides. In fact, practically, I find Google Chrome Remote Desktop to be the easiest software to deal with, although, personally, I am not a big fun of it. Historically, Google Chrome Remote Desktop was the easiest to install, and when I came to my work, everyone would understand it. For example, I could say: \"Oh, just use Chrome Remote Desktop\", and my colleagues would get it without any further explanation. Convenient, isn't it.</p> <p>Anyhow, it is time to step forward, we are acquiring new equipment, and I am going to setup a complex system with ability to give remote access to our equipment on demand whenever and wherever I am situated. For this, I have continued my experiments with various remote-desktop-software, and, here, I will document some of my findings. Starting from RustDesk. First of all, I found that for self-hosting, we need to use a pair of programs, RustDesk as a client, and RustDesk Server as a server applications. I set the server application on an AWS EC2 instance, what was relatively easy. And, following guidelines I found on the internet, I shared the ID, Relay Server, and Key with the client app. It all seemed to be working on the first day, but, on the second day, it would fail to connect to the server on my Windows machine, but wouldn't fail on my Linux machine. Also, I had to use xrdp instead of built-in gnome remote desktop on Ubuntu 24.04 because it wouldn't work the way I want it to causing me black screens.</p> <p> </p> <p>Eventually, I stumbled upon Guacamole, following guidelines on the internet, I installed it natively on the Ubuntu 24.04. Notably, Ubuntu 24.04 doesn't provide Tomcat 9 because they moved forward to Tomcat 10. However, Guacamole doesn't like Tomcat 10, but it has not problems with Tomcat 9. To solve this problem, I had to download files directly from the Tomcat website. Luckily, installation was straight forward. The reason I didn't go with the version 10 was because Guacamole didn't support that version at that time. Not sure how it is like now. Furtermore, marrying Guacamole version 1.5.5 with gnome remote desktop was impossible. Apparently, there is a bug related with that version of Guacamole. Again, to solve this problem, I had to clone the official mirror repository of Guacamole on GitHub. After this, it seemed to be working, fingers crossed...</p> <p>To install Guacamole server-side service, start by installing dependencies:</p> <pre><code>sudo apt install build-essential libcairo2-dev libjpeg-turbo8-dev \\\n    libpng-dev libtool-bin libossp-uuid-dev libvncserver-dev \\\n    freerdp2-dev libssh2-1-dev libtelnet-dev libwebsockets-dev \\\n    libpulse-dev libvorbis-dev libwebp-dev libssl-dev \\\n    libpango1.0-dev libswscale-dev libavcodec-dev libavutil-dev \\\n    libavformat-dev\n</code></pre> <p>Then, install server-side service.</p> <pre><code>git clone https://github.com/apache/guacamole-server\ncd guacamole-server\nautoreconf -fi\nsudo ./configure --with-init-dir=/etc/init.d --enable-allow-freerdp-snapshots\nsudo make\nsudo make install\n</code></pre> <p>After installation of the service, I continued to configuring the service.</p> <pre><code>sudo ldconfig\nsudo systemctl daemon-reload\nsudo systemctl start guacd\nsudo systemctl enable guacd\n</code></pre> <p>As a rule of thumb, I also checked the status of the service.</p> <pre><code>sudo systemctl status guacd\n</code></pre> <p>This I just followed the guide as I had no problems with creating folders at this stage either.</p> <pre><code>sudo mkdir -p /etc/guacamole/{extensions,lib}\n</code></pre> <p>From now on, I focused on Tomcat 9.</p> <pre><code>sudo apt install openjdk-17-jdk\nsudo useradd -m -U -d /opt/tomcat -s /bin/false tomcat\nsudo wget https://downloads.apache.org/tomcat/tomcat-9/v9.0.96/bin/apache-tomcat-9.0.96.tar.gz -P /tmp\nsudo tar -xvf /tmp/apache-tomcat-9.0.96.tar.gz -C /opt/tomcat\nsudo chown -R tomcat:tomcat /opt/tomcat\n</code></pre> <p>Tomcat is installed, we proceed to configure it.</p> <pre><code>cd /etc/systemd/system\nsudo nvim tomcat.service\n</code></pre> <p>Once I created the file, I paste in the following configuration.</p> <pre><code>[Unit]\nDescription=Tomcat Server\nAfter=network.target\n\n[Service]\nType=forking\nUser=tomcat\nGroup=tomcat\nEnvironment=\"JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64\"\nWorkingDirectory=/opt/tomcat/apache-tomcat-9.0.96\nExecStart=/opt/tomcat/apache-tomcat-9.0.96/bin/startup.sh\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Restarting services to let it pick up the changes won't hurt at this stage.</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start tomcat\nsudo systemctl enable tomcat\n</code></pre> <p>At this point, if I access the service at port 8080, it should render a page saying all is working. Now, I can focus my attention on Guacamole Web App client.</p> <pre><code>sudo wget https://downloads.apache.org/guacamole/1.5.5/binary/guacamole-1.5.5.war\nsudo mv guacamole-1.5.5.war /opt/tomcat/apache-tomcat-9.0.96/webapps/guacamole.war\nsudo systemctl restart tomcat guacd\n</code></pre> <p>This is a \"production-ready\" approach, so we use a database for user authentication instead of a simple XML-file as was documented in the official manual.</p> <pre><code>sudo apt install mariadb-server -y\nsudo mysql_secure_installation\n</code></pre> <p>As a note, I didn't use unix_sockets, but a regular password. The rest I left at default arguments. Next, the guide was suggesting to download an older version of a MySQL/J connector (v8.0.26), but I felt brave, and download the latest version 9.1.0. The download procedure was different for me for some reason. I had to manually download file from the website.</p> <pre><code>sudo apt install ./mysql-connector-j_9.1.0-1ubuntu24.04_all.deb\nsudo cp /usr/share/java/mysql-connector-j-9.1.0.jar /etc/guacamole/lib/\n</code></pre> <p>Next, I focused on the Apache Guacamole JDBC AUTH plugin.</p> <pre><code>sudo wget https://downloads.apache.org/guacamole/1.5.5/binary/guacamole-auth-jdbc-1.5.5.tar.gz\nsudo tar -xf guacamole-auth-jdbc-1.5.5.tar.gz\nsudo mv guacamole-auth-jdbc-1.5.5/mysql/guacamole-auth-jdbc-mysql-1.5.5.jar /etc/guacamole/extensions/\n</code></pre> <p>Now, it is time to configure our database.</p> <pre><code>sudo mysql -u root -p\n</code></pre> <p>These are the commands inside MariaDB.</p> <pre><code>MariaDB [(none)]&gt; CREATE DATABASE guac_db;\nMariaDB [(none)]&gt; CREATE USER 'guac_user'@'localhost' IDENTIFIED BY 'password';\nMariaDB [(none)]&gt; GRANT SELECT,INSERT,UPDATE,DELETE ON guac_db.* TO 'guac_user'@'localhost';\nMariaDB [(none)]&gt; FLUSH PRIVILEGES;\nMariaDB [(none)]&gt; EXIT;\n</code></pre> <p>After, we want to apply a schema.</p> <pre><code>cd guacamole-auth-jdbc-1.5.5/mysql/schema\ncat *.sql | mysql -u root -p guac_db\n</code></pre> <p>Next, we should tell Guacamole how it should handle user data. We create a simple properties file.</p> <pre><code>sudo nvim /etc/guacamole/guacamole.properties\n</code></pre> <p>And, populate it with the configuration below.</p> <pre><code># MySQL properties\nmysql-hostname: 127.0.0.1\nmysql-port: 3306\nmysql-database: guac_db\nmysql-username: guac_user\nmysql-password: password\n</code></pre> <p>Restart all relevant services.</p> <pre><code>sudo systemctl restart tomcat guacd mysql\n</code></pre> <p>Now, the service should be accessible at port <code>8080/guacamole</code>, and default login and password should be <code>guacadmin</code>. At this point, it is strongly recommended to create a new admin user and password and delete the default credentials. To do this, from the guacadmin profile click on Settings. Under the Edit User section, enter your new username and password. Then, under the Permissions section check the all boxes. When you are done, click Save. Now log out from the default user and log in back to Apache Guacamole with your new user created. Then, navigate to the settings, and users tab, and delete the guacadmin user. That\u2019s it, you are done. From there, you can securely access your servers and computers.</p> <p>References:</p> <ul> <li>Guide to install Guacamole server program</li> <li>Guide to install Tomcat 9 on Ubuntu 24.04</li> <li>Here I found how to build Guacamole from GitHub repository</li> <li>This is the mirror repository of Apache Guacamole on GitHub</li> <li>The website where I download MySQL/J connector</li> </ul>"},{"location":"manual/#virtualisation","title":"Virtualisation","text":"<p>When working with VirtualBox, to enable bridge network, it is a simple matter of changing networking adapter in the settings of the progam to bridge adapter with the real ethernet adapter selected below. However, VirtualBox doesn't let us do hardware passthrough or, at least, I didn't find a definite answer to this on the internet. Otherwise, VirtualBox is a very useful piece of software that I use from time to time to experiment with various OS and new software.</p> <p>Moving to QEMU/KVM, to allow virtual machines to connect to outside world the host's network should be reconfigured. The <code>swtpm</code> package is reponsible for TPM emulation. I used it to satisfy Windows 11 installation requirement. The <code>virtiofsd</code> package is needed to share folders between the host and guests. The guides at [1, 2, 3] suggested to install WinFSP on Windows and enable Virtio FS service. However, I had compatibility issues installing <code>virtio-win-tools</code>. They were disabling my mouse. Instead, I manually applied the driver in Device Manager by right-clicking on it and selecting Update driver option. As for the service, I manually recreated the path to the executable and copied it from the <code>virtio-win</code> CD-ROM, e.g. <code>virtiofsd.exe</code> and <code>virtiofsd.pdb</code>. The following commands were used to create the service.</p> <pre><code>sc create VirtioFsSvc binpath=\"C:\\Program Files\\Virtio-Win\\VioFS\\virtiofs.exe\" start=auto depend=\"WinFsp.Launcher/VirtioFsDrv\" DisplayName=\"Virtio FS Service\"\nsc start VirtioFsSvc\n</code></pre> <p>Experimentally, I have found that I don't have to install <code>edk2-ovmf</code> on Ubuntu because I could choose Secure Boot in <code>virt-manager</code> without it. However, on Arch Linux, it seems necessarily. To install QEMU/KVM with Virtual Manager to the following:</p> <pre><code>sudo apt install qemu-kvm libvirt-daemon libvirt-daemon-system bridge-utils virt-manager swtpm virtiofsd\n</code></pre> <p>Usually, on Ubuntu 24.04.1, user is already part of <code>libvirt</code>, so we just need to add the user to the <code>kvm</code> group.</p> <pre><code>sudo adduser $USER kvm\n</code></pre> <p>Once the user is added to the groups, I would suggest rebooting. After reboot, we can check if the installation is correct by checking if there are any virtual machines on the system.</p> <pre><code>sudo virsh list --all\n</code></pre> <p>Or, we can check status of the <code>libvirt</code> daemon.</p> <pre><code>sudo systemctl status libvirtd\n</code></pre> <p>Then, we can create bridge interface. Although, the default NAT allows VMs to communicate with the host and each other. And, through port forwarding on the host, we can expose the VMs to the outside world.</p> <pre><code>nmcli con show\nnmcli con add ifname br0 type bridge con-name br0\nnmcli con add type bridge-slave ifname eth0 master br0\nnmcli con mod br0 bridge.stp no\nnmcli con down eth0\nnmcli con up br0\nnmcli device show\nsudo systemctl restart NetworkManager.service\n</code></pre> <p>Although, creating bridges seems to be the most logical approach, sometimes, we can't use them. Therefore, port forwarding seems to be a viable alternative. Here is how to forward ports from host physical interface to virtual interface where the guest VMs reside.</p> <pre><code>iptables -t nat -I PREROUTING -p tcp -d HOST_IP --dport HOST_PORT -j DNAT --to-destination GUEST_IP:GUEST_PORT\niptables -I FORWARD -m state -d GUEST_IP/24 --state NEW,RELATED,ESTABLISHED -j ACCEPT\n</code></pre> <p>For now, I am using <code>iptables-persistent</code> to save/reload port forwarding rules between reboots.</p> <pre><code>sudo apt install iptables-persistent\n</code></pre> <p>The location is saves the rules in is <code>/etc/iptables/rules.v4</code> and <code>/etc/iptables/rules.v6</code>. To save the rules and load them, I use the following commands. I had to wrap it around as a command for a bash because I need elevated privilages on both piping as well as saving commands.</p> <pre><code>sudo bash -c \"iptables-save &gt; /etc/iptables/rules.v4\"\n</code></pre> <p>To setup static IP inside guest VM, we need to modify the netplan configuration file for the NetworkManager service.</p> <pre><code>network:\n    version: 2\n    renderer: NetworkManager\n    ethernets:\n        INTERFACE_NAME:\n            dhcp4: false\n            addresses:\n                - STATIC_IP/24\n            routes:\n                - to: default\n                 via: HOST_IP\n            nameservers:\n                addresses: [HOST_IP]\n</code></pre> <p>For example, <code>INTERFACE_NAME=eth0</code>, <code>STATIC_IP=192.168.1.100</code>, <code>HOST_IP=192.168.1.1</code>. Save the aforementioned in the <code>/etc/netplan/01-network-manager-all.yaml</code> file. And, apply the plan.</p> <pre><code>sudo chmod 700 /etc/netplan/01-network-manager-all.yaml\nsudo netplan try\n</code></pre> <p>Then, we setup KVM to allow guest VMs to use bridge interface. Start from creating a file in an arbitrary location on the computer and name it <code>host-birdge.xml</code>.</p> <pre><code>&lt;network&gt;\n    &lt;name&gt;host-bridge&lt;/name&gt;\n    &lt;forward mode=\"bridge\"/&gt;\n    &lt;bridge name=\"br0\"/&gt;\n&lt;/network&gt;\n</code></pre> <p>Then execute these commands (as a user in the libvirt group):</p> <pre><code>virsh net-define host-bridge.xml\nvirsh net-start host-bridge\nvirsh net-autostart host-bridge\n</code></pre> <p>A mechanism to allow connections from outside.</p> <pre><code>sudo modprobe br_netfilter\nsudo echo \"br_netfilter\" &gt; /etc/modules-load.d/br_netfilter.conf\n</code></pre> <p>Create /etc/sysctl.d/10-bridge.conf.</p> <pre><code># Do not filter packets crossing a bridge\nnet.bridge.bridge-nf-call-ip6tables=0\nnet.bridge.bridge-nf-call-iptables=0\nnet.bridge.bridge-nf-call-arptables=0\n</code></pre> <p>Apply and check the config.</p> <pre><code>sudo sysctl -p /etc/sysctl.d/10-bridge.conf\nsudo sysctl -a | grep \"bridge-nf-call\"\n</code></pre> <p>Configure the guest to use host-bridge. Open up the Virtual Machine Manager and then select the target guest. Go to the NIC device. The drop down for \"Network Source\" should now include a device called \"Virtual netowrk 'host-bridge'\". The \"Bridge network device model\" will be \"virtio\" if that's your KVM configuration's default. Select that \"host-bridge\" device.</p> <p>Useful commands:</p> <p>A command to set automatic start of VMs when host boots up.</p> <pre><code>virsh autostart &lt;vm-name&gt;\n</code></pre> <p>A command to undo automatic start of VMs when host boots up.</p> <pre><code>virsh autostart --disable &lt;vm-name&gt;\n</code></pre> <p>A command to set automatic start of the Docker containers when host boots up.</p> <pre><code>docker update --restart unless-stopped &lt;container-name&gt;\n</code></pre> <p>A command to undo automatic start of the Docker containers when host boots up.</p> <pre><code>docker update --restart no &lt;container_name_or_id&gt;\n</code></pre> <p>Alternative to <code>iptables</code> could be <code>nginx</code></p> <p>It is possible to configure <code>nginx</code> as a reverse proxy server on a host machine. That way, all traffic could be forwarded to an appropriate guest machine. Furthermore, using OpenResty with Lua, it is possible to configure it to pull forwarding rules from a database like MySQL, PostgreSQL, etc. Building on top, a FastAPI server would update the rules via a simple REST API endpoint. At the end, a user-oriented web application could be developed using Rest.js, Vue.js, or AngularJS. That would constitute a fully automated user-friendly system for host-guest VM management.</p> <p>References: * Guide to add a bridge interface to the Ubuntu desktop using nmcli * Another guide to add a bridge interface that helped to understand how to set dynamic IP instead of static * Guide to setup a bridged network for KVM guests * Another useful guide, this is where I started my research from * 1/3 of QEMU/KVM Ubuntu 24.04 installation instructions I used * 2/3 of QEMU/KVM Ubuntu 24.04 installation instructions I used * 3/3 of QEMU/KVM Ubuntu 24.04 installation instructions I used * 1/3 of port forwarding instructions I used * 2/3 of port forwarding instructions I used * 3/3 of port forwarding instructions I used * 1/2 of setting static IP using netplan and NetworkManager * 2/2 of setting static IP using netplan and NetworkManager</p>"},{"location":"manual/#gpu-passthrough","title":"GPU Passthrough","text":"<p>I decided to make it into a separate section because this task is complex enough on its own.</p> <p>The following command can tell what kernel driver is in use.</p> <pre><code>lspci | grep ' VGA ' | cut -d\" \" -f 1 | xargs -i lspci -v -s {}\n</code></pre> <p>The output should look something like this.</p> <pre><code>bd:00.0 VGA compatible controller: NVIDIA Corporation GA102GL [RTX A6000] (rev a1) (prog-if 00 [VGA controller])\n    Subsystem: NVIDIA Corporation GA102GL [RTX A6000]\n    Physical Slot: 7\n    Flags: bus master, fast devsel, latency 0, IRQ 439, NUMA node 1, IOMMU group 30\n    Memory at e9000000 (32-bit, non-prefetchable) [size=16M]\n    Memory at 22bfe0000000 (64-bit, prefetchable) [size=256M]\n    Memory at 22bff0000000 (64-bit, prefetchable) [size=32M]\n    I/O ports at d000 [size=128]\n    Expansion ROM at ea000000 [virtual] [disabled] [size=512K]\n    Capabilities: &lt;access denied&gt;\n    Kernel driver in use: nvidia\n    Kernel modules: nvidiafb, nouveau, nvidia_drm, nvidia\n</code></pre> <p>For a successful GPU passthrough, I installed Ubuntu 24.04.1 without NVIDIA drivers using only nouveau.</p> <p>Modify grub.</p> <pre><code>sudo nvim /etc/default/grub\n</code></pre> <p>Make it look like this.</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash intel_iommu=on iommu=pt\"\n</code></pre> <p>Save the changes, and update grub to apply the changes. Following with a reboot.</p> <pre><code>sudo update-grub\n</code></pre> <p>Blacklist the GPUs by creating a configuration file.</p> <pre><code>sudo nvim /etc/modprobe.d/gpu-passthrough-blacklist.conf\n</code></pre> <p>Make it look like this.</p> <pre><code>blacklist nouveau\nblacklist snd_hda_intel\n</code></pre> <p>Bind GPUs to VFIO by creating another configuration file.</p> <pre><code>sudo nvim /etc/modprobe.d/vfio.conf\n</code></pre> <p>Make it look like this.</p> <pre><code>options vfio-pci ids=XXXX:XXXX,YYYY:YYYY\n</code></pre> <p><code>XXXX:XXXX,YYYY:YYYY</code> are model ids found by using the <code>lspci -nnk | grep -e NVIDIA</code> command. The ids are located at the end of the line. Shortly after, save and apply the changes.</p> <pre><code>sudo update-initramfs -u\n</code></pre> <p>Example</p> <p>Installing Ubuntu 24.04.1 from a USB flash drive. A standard procedure, however, on the step where it asks to isntall third-party drivers, we leave the checkbox empty. The \"Download and install support for additional media formats\" was greyed out because the machine didn't have access to the internet. The goal is to ensure that the GPUs wouldn't be used by the host system but rather on-demand by guest VMs.</p> <p>The system has failed to boot on the first try. Rebooted, but the screen was black. Switched to tty3 and enabled Xorg suppport in the <code>gdm3</code> configuration file. Rebooted and logged in. The welcome page has been through, and connection to the internet was done via Wi-Fi.</p> <p>Given the access to the WWW, the system was updated and upgraded. Notebly, the connection was very slow, i.e. it took around 30 minutes to complete the task. It prompted me to restart, we went with \"Restart later\" and then manually restarted. Enabled RDP and SSH.</p> <p>Followed instructions to perform initial configuration. Skipped <code>build-essential</code>, <code>ubuntu-restricted-extras</code>, <code>ffmpeg</code>, <code>fonts-powerline</code>, <code>gstreamer</code>, and <code>wget</code>. Proceeded with the Virtualisation instructions. It is very important to skip the <code>sudo apt upgrade</code> because it changes some of the packages that make gdm3 fail to start when blacklisting nouveau! That was a big issue and it took me two days to narrow it down to this point. As it wasn't neccessary to upgrade, I left it at this stage.</p> <pre><code>gpu0/gpuall SSH will be available at 192.168.122.100:221.\n            RDP will be available at 192.168.122.100:33891.\n\ngpu1/gpuduo1 SSH will be available at 192.168.122.101:221.\n             RDP will be available at 192.168.122.101:33891.\n\ngpu2/gputrio SSH will be available at 192.168.122.102:221.\n             RDP will be available at 192.168.122.102:33891.\n\ngpu3/gpuduo2 SSH will be available at 192.168.122.103:221.\n             RDP will be available at 192.168.122.103:33891.\n\nfileserver SSH will be available at 192.168.122.104:221.\n           RDP will be available at 192.168.122.104:33891.\n           MinIO will be available at 192.168.122.104:9000.\n           MinIO Dashboard will be available at 192.168.122.104:9001.\n</code></pre> <p>References: * A guide to setup GPU passthrough * A guide to setup GPU passthrough * A guide to setup GPU passthrough * How to lspci to check GPU kernel driver in use * The comment in this link was intriguing * 1/2 of the guide the comment was referring to * 2/2 of the guide the comment was referring to</p>"},{"location":"manual/#gpu-passthrough-for-arch","title":"GPU Passthrough for Arch","text":"<p>A simple Bash script that will give you all the valuable IOMMU information, e.g. <code>10de:2882</code> or <code>10de:22be</code>. The script is available at <code>project/dotfiles/.local/bin/iommu</code> and I usually install it at <code>~/.local/bin/iommu</code>.</p> <pre><code>    #!/bin/bash\n\n    for d in /sys/kernel/iommu_groups/*/devices/*; do\n        n=${d#*/iommu_groups/*}; n=${n%%/*}\n        printf 'IOMMU Group %s ' \"$n\"\n        lspci -nns \"${d##*/}\"\n    done\n</code></pre> <p>The guide [1, 2, 3] has mentioned ACS kernel patch, which allows the system to split the hardware devices into separate IOMMU groups. What in turn should provide higher granularity over the devices we want to pass through. I skipped this step.</p> <p>Modifed <code>/etc/default/grub</code> by adding the following to <code>GRUB_CMDLINE_LINUX_DEFAULT</code>.</p> <pre><code>amd_iommu=on iommu=pt vfio-pci.ids=10de:21c4,10de:1aeb\n</code></pre> <p>Once you've got all these options set, go ahead commit the changes. And, reboot.</p> <pre><code>sudo grub-mkconfig -o /boot/grub/grub.cfg\n</code></pre> <p>After reboot, the output of <code>dmesg | grep vfio</code> indicated that the <code>vfio</code> module wasn't loaded during the boot. Logically, the selected PCI devices weren't used by <code>vfio</code> drivers. To circum nagivate this behaviour, I had to modify <code>/etc/mkinitcpio.conf</code> file.</p> <p>UPDATE: it seems like <code>vfio_virqfd</code> module is built in <code>vfio</code> [1]. Logically, I removed it from the <code>MODULES</code> list.</p> <pre><code>MODULES=(vfio_pci vfio vfio_iommu_type1)\n</code></pre> <p>I saved the file, and ran the following.</p> <pre><code>sudo mkinitcpio -p linux\n</code></pre> <p>The following command installed the required software to create a VM. The core are <code>qemu libvirt</code>. However, I use <code>virt-manager</code> GUI for easier management. The <code>dmidecode</code> package is one of the dependencies that is needed by <code>virt-manager</code>, I think. I know that somewhere along the journey, it would try to create a network which would use <code>dnsmasq</code>. The <code>edk2-ovmf</code> package is a UEFI firmware for virtual machines based on EDK II (EFI Development Kit). The <code>swtpm</code> package is needed to bypass TMP 2.0 requirement by Windows 10/11. When prompted, I selected the third option: qemu-full.</p> <pre><code>sudo pacman --sync qemu libvirt virt-manager edk2-ovmf dnsmasq dmidecode swtpm\n</code></pre> <p>Start the libvirt daemon.</p> <pre><code>sudo systemctl enable --now libvirtd\nsudo systemctl enable --now virtlogd.socket\n</code></pre> <p>Activate the default network and make it persistent between bootings.</p> <pre><code>sudo virsh net-start default\nsudo virsh net-autostart default\n</code></pre> <p>Either use polkit with polkit-gnome or add to the <code>libvirt</code> group.</p> <pre><code>sudo usermod -aG libvirt $USER\n</code></pre>"},{"location":"manual/#software-raid","title":"Software RAID","text":"<p>From the internet search, the suggested tool is <code>mdadm</code>.</p> <p>To install <code>mdadm</code>, run the following command in terminal.</p> <pre><code>sudo apt install mdadm\n</code></pre> <p>The following command will create the RAID 5 array.</p> <pre><code>sudo mdadm --create --verbose /dev/md0 --level=5 --raid-devices=3 /dev/sda /dev/sdb /dev/sdc\n</code></pre> <p>Format the RAID array and make it persistent.</p> <pre><code>clear; sudo mkdir -p /mnt/md0\nsudo mount /dev/md0 /mnt/md0/\ndf -h -x devtmpfs -x tmpfs\n</code></pre> <p>Then, inside the host machine, we can setup something like this.</p> <pre><code>sudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf\nsudo update-initramfs -u\nsudo echo '/dev/md0 /box ext4 defaults,nofail,discard 0 0' | sudo tee -a /etc/fstab\n</code></pre> <p>References: * The 1/2 guide * The 2/2 guide</p>"},{"location":"manual/#bios-raid","title":"BIOS RAID","text":"<p>Set the SATA from <code>AHCI</code> to <code>RAID</code>.</p> <p>Created volume under <code>Advanced/Intel(R) VROC sSATA Controller/Create RAID Volume</code>.</p> <p>Unfortunately, my configuration doesn't support <code>Intel(R) VROC sSATA Controller</code>. I will have to use software RAID.</p> <pre><code>CPU: Intel(R) Xeon(R) Silver 4410Y\nGeneration: 4th \"Sapphire Rapids\"\nChipset: Intel\u00ae C621A Chipset\n</code></pre> <p>References: * Intel\u00ae Virtual RAID on CPU (Intel\u00ae VROC) Operating Systems Support List * Release Notes Intel\u00ae Virtual RAID on CPU (Intel\u00ae VROC) for Linux* * Intel\u00ae Xeon\u00ae Silver 4410Y Processor * Intel\u00ae Virtual RAID on CPU (Intel\u00ae VROC) Linux* Driver for Intel\u00ae Server Boards and Systems Based on Intel\u00ae 621A Chipset * GPU SuperServer SYS-740GP-TNRT</p>"},{"location":"manual/#vm-for-minio","title":"VM for MinIO","text":"<p>To setup a file storage server for research work, we will setup MinIO on Ubuntu 24.04. For this, we will run a VM using KVM/QEMU. We already set up RAID 5 on the host machine and, simply, created virtual disk using entire available space.</p> <p>Waiting for Ubuntu to install inside VM...</p> <p>Used <code>parted</code> command line tool to partition and format the hard drive.</p> <p>Modified <code>fstab</code> to add automount option. And, used UUID instead of a path because it is more reliable.</p> <p>Below are commands to run a Docker container of MinIO.</p> <pre><code>mkdir -p ${HOME}/minio/data\n\ndocker run \\\n-p 9000:9000 \\\n-p 9001:9001 \\\n--user $(id -u):$(id -g) \\\n--name minio1 \\\n-e \"MINIO_ROOT_USER=ROOTUSER\" \\\n-e \"MINIO_ROOT_PASSWORD=CHANGEME123\" \\\n-v ${HOME}/minio/data:/data \\\nquay.io/minio/minio server /data --console-address \":9001\"\n</code></pre> <p>References: * The tutorial I used to setup virtual disk in guest OS.</p>"},{"location":"manual/#what-are-base-devel-dependencies","title":"What are <code>base-devel</code> Dependencies","text":"<p>List of dependencies that <code>base-devel</code> brings with itself. To highlight that <code>base-devel</code> is optional, at least in theory, I put it in the post-installation section [1].</p> <ul> <li>archlinux-keyring</li> <li>autoconf</li> <li>automake</li> <li>binutils</li> <li>bison</li> <li>debugedit</li> <li>fakeroot</li> <li>file</li> <li>findutils</li> <li>flex</li> <li>gawk</li> <li>gcc</li> <li>gettext</li> <li>grep</li> <li>groff</li> <li>gzip</li> <li>libtool</li> <li>m4</li> <li>make</li> <li>pacman</li> <li>patch</li> <li>pkgconf</li> <li>sed</li> <li>sudo</li> <li>texinfo</li> <li>which</li> </ul>"},{"location":"manual/#how-to-install-dwm-and-dmenu-from-source-code","title":"How to Install <code>dwm</code> and <code>dmenu</code> from Source Code","text":"<p>The <code>dwm</code> and <code>dmenu</code> packages have the following dependencies on Arch Linux: <code>base-devel git libx11 libxft xorg-server xorg-xinit terminus-font</code> [1]. The fonts are optional. And, the former guide used <code>st</code> but I opted for <code>alacritty</code>.</p> <pre><code>mkdir -p ~/.local/src\ngit clone git://git.suckless.org/dmenu ~/.local/src/dmenu\ngit clone git://git.suckless.org/dwm ~/.local/src/dwm\n</code></pre> <p>To install <code>dmenu</code>.</p> <pre><code>cd ~/.local/src/dmenu\nnvim config.mk\n</code></pre> <p>Edit <code>config.mk</code> to avoid <code>sudo</code> in <code>sudo make install</code>, I modified <code>config.mk</code> by changing the prefix to <code>~/.local</code> [1].</p> <pre><code># XINERAMALIBS  = -lXinerama\n# XINERAMAFLAGS = -DXINERAMA\n</code></pre> <p>Compile and install.</p> <pre><code>make clean\nmake install\n</code></pre> <p>To install <code>dwm</code>.</p> <pre><code>cd ~/.local/src/dwm\nnvim config.mk\n</code></pre> <p>Edit <code>config.mk</code> to achieve the same as earlier.</p> <pre><code># XINERAMALIBS  = -lXinerama\n# XINERAMAFLAGS = -DXINERAMA\n</code></pre> <p>Compile and install.</p> <pre><code>make clean\nmake install\n</code></pre> <p>Make the <code>dwm</code> executable available to the entire user-space system.</p> <pre><code>nvim ~/.bashrc\n</code></pre> <p>Edit <code>.bashrc</code> file.</p> <pre><code>PATH=~/.local/bin:$PATH\n</code></pre> <p>Copy <code>.xinitrc</code> from default location to home folder for customisation [1].</p> <pre><code>cp /etc/X11/xinit/xinitrc ~/.xinitrc\nnvim ~/.xinitrc\n</code></pre> <p>Edit <code>.xinitrc</code> file.</p> <pre><code>exec dwm\n</code></pre> <p>After, when ready to switch to GUI run the following.</p> <pre><code>clear ; startx\n</code></pre> <p>There are many shortcuts to remember [1]. </p>"},{"location":"manual/#how-to-customise-dwm-and-dmenu","title":"How to Customise <code>dwm</code> and <code>dmenu</code>","text":"<p>The suckless software is customised primarily through patches [1, 2, 3]. These patches in turn modify the source code that is written in C. To apply a patch issue a command such as like: <code>patch &lt; path/to/patch.diff</code>. I would recommend to issue the commands from the root folder of a project. Also, <code>*.rej</code> contains changes that were rejected due to conflicts. These changes must be handled manually [1].</p> <p>Applied the patches for <code>dwm</code> in order of appearance: bar height, barpadding, vanitygapps.</p> <p>The <code>config.h</code> file is a generated file and, in my case, was own by <code>root</code>. Therefore, it was easier to modify <code>config.def.h</code> file and remove <code>config.h</code> when rebuilding.</p> <p>To set custom fonts, e.g. Terminus, Tamzen, JetBrains Mono, Hack, and Source Code Pro, change the arguments from <code>\"monospace:size=10\"</code> to <code>\"xos4 Terminus:pixelsize=14\"</code> in <code>config.def.h</code>.</p> <pre><code>    static const unsigned int borderpx  = 2;  /* border pixel of windows */\n    static const unsigned int gappiv    = 10; /* vert inner gap between windows */\n    static const int user_bh            = 10; /* 2 is the default spacing around the bar's font */\n    static const int vertpad            = 10; /* vertical padding of bar */\n    static const int sidepad            = 10; /* horizontal padding of bar */\n    static const char *fonts[]          = { \"xos4 Terminus:pixelsize=14\" };\n    static const char dmenufont[]       = \"xos4 Terminus:pixelsize=14\";\n</code></pre> <p>The patches for <code>dmenu</code>: bar height, border, case-insensitive, center.</p> <pre><code>    static const int user_bh   = 10; /* add an defined amount of pixels to the bar height */\n    static const char *fonts[] = { \"xos4 Terminus:pixelsize=14\" };\n    /* -l option; if nonzero, dmenu uses vertical list with given number of lines */\n    static unsigned int lines  = 5;\n    /* Size of the window border */\n    static unsigned int border_width = 2;\n</code></pre> <p>Things I need in a status bar:</p> <ol> <li>Time &amp; date</li> <li>Volume level</li> <li>Wi-Fi status</li> <li>Bluetooth status</li> <li>TBD</li> </ol> <p>A script that achieves this is available at <code>project/dotfiles/.local/bin/status</code>. I usually copy it over to <code>~/.local/bin/status</code>. An example is displayed below. If there are squares instead of icons then the system is either missing the right fonts that supports icons or the text editor is misconfigured.</p> <pre><code>    #!/bin/bash\n\n    while true; do\n        # Volume\n        VOL=$(wpctl get-volume @DEFAULT_AUDIO_SINK@ | awk '{printf(\"%d\", $2 * 100)}')\n\n        # Time\n        TIME=$(date '+%Y/%m/%d %H:%M:%S')\n\n        # Wi-Fi\n        WIFI=$(nmcli -t -f active,ssid dev wifi | grep '^yes' | cut -d: -f2)\n        SIGNAL=$(nmcli -t -f active,ssid,signal dev wifi | grep '^yes' | cut -d: -f3)\n\n        # Bluetooth\n        BT_INFO=$(bluetoothctl info)\n        BT_CONNECTED=$(echo \"$BT_INFO\" | grep \"Connected:\" | awk '{print $2}')\n        if [ \"$BT_CONNECTED\" = \"yes\" ]; then\n            BT_NAME=$(echo \"$BT_INFO\" | grep \"Name:\" | cut -d ' ' -f2-)\n            BT_RAW_RSSI=$(echo \"$BT_INFO\" | grep \"RSSI:\" | awk '{print $2}')\n        BT_DEC_RSSI=$(printf \"%d\" \"$BT_RAW_RSSI\")\n\n        # Signal quality based on dBm.\n        if [ \"$BT_DEC_RSSI\" -ge -60 ]; then\n                BT_QUALITY=\"Excellent\"\n            elif [ \"$BT_DEC_RSSI\" -ge -70 ]; then\n                BT_QUALITY=\"Good\"\n            elif [ \"$BT_DEC_RSSI\" -ge -80 ]; then\n                BT_QUALITY=\"Fair\"\n            else\n                BT_QUALITY=\"Poor\"\n            fi\n\n\n            BT_STATUS=\"\uf293 ${BT_NAME} (${BT_DEC_RSSI} dBm, ${BT_QUALITY})\"\n        else\n            BT_STATUS=\"\uf293 Disconnected\"\n        fi\n\n        # Set status bar\n        xsetroot -name \"\uf028  ${VOL}% | \uf1eb  ${WIFI:-Disconnected} (${SIGNAL:-0}%) | ${BT_STATUS} | ${TIME}\"\n\n        sleep 1\n    done\n</code></pre>"},{"location":"manual/#new-way-to-passthrough-a-gpu","title":"New Way to Passthrough a GPU","text":"<p>Enable IOMMU [1] in <code>/etc/default/grub</code>. Both Arch and Ubuntu will have this file if the installed OS uses GRUB to boot.</p> <p>=== Method 1</p> <pre><code>=== Intel\n\n    ```bash\n    GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash intel_iommu=on iommu=pt\"\n    ```\n\n=== AMD\n\n    ```bash\n    GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash amd_iommu=on iommu=pt\"\n    ```\n</code></pre> <p>=== Method 2</p> <pre><code>This tells the system: _\"Any device with PCI vendor:device ID matching 10de:1111 or 10de:1112 should be bound to `vfio-pci`.\"_\n\n=== Intel\n\n    ```bash\n    GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash intel_iommu=on iommu=pt vfio-pci.ids=10de:2882,10de:22be\"\n    ```\n\n=== AMD\n\n    ```bash\n    GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash amd_iommu=on iommu=pt vfio-pci.ids=10de:2882,10de:22be\"\n    ```\n</code></pre> <p>Why the first method is better than the second method? Well, imagine the following situation.</p> <ul> <li><code>gpu1</code>: 10de:1111,10de:1112</li> <li><code>gpu2</code>: 10de:1111,10de:1112</li> <li><code>gpu3</code>: 10de:2221,10de:1112</li> </ul> <p>We would like to pass <code>gpu1</code> and <code>gpu2</code> that share the same IDs to <code>vfio-ci</code>, and <code>gpu3</code> should be untouched. Here's where it gets tricky, if gpu3 also includes components (like audio controllers) that share the same PCI IDs as those listed (e.g., 10de:1111 or 10de:1112), then they will be bound to vfio-pci too \u2014 even if the GPU itself doesn't match directly.</p> <p>So, instead of using <code>vfio-pci.ids</code>, which uses IDs globally, use device-specific binding based on PCI addresses (Bus:Device.Function). Identify the full PCI addresses of the devices you want to passthrough (and only those). Create a script to bind specific devices, <code>/usr/local/bin/vfio-bind.sh</code>. Make sure your vfio-pci binding script runs early enough in the boot process to grab the devices before any other driver claims them. There are a few ways to do this on Ubuntu, but the cleanest and most robust is using a <code>systemd</code> service that runs at the right time\u2014before device drivers initialize but after the necessary sysfs paths exist. Substitute <code>0000:01:00.0 0000:01:00.1 0000:02:00.0 0000:02:00.1</code> with your PCI addresses.</p> <pre><code>#!/bin/bash\n\n# Load vfio-pci.\nmodprobe vfio-pci\n\n# Use driver_override (cleaner way).\nfor dev in 0000:01:00.0 0000:01:00.1 0000:02:00.0 0000:02:00.1; do\n  echo \"vfio-pci\" &gt; /sys/bus/pci/devices/$dev/driver_override\ndone\n\n# Bind the devices.\nfor dev in 0000:01:00.0 0000:01:00.1 0000:02:00.0 0000:02:00.1; do\n  echo $dev &gt; /sys/bus/pci/drivers/vfio-pci/bind\ndone\n</code></pre> <p>Make it executable:</p> <pre><code>sudo chmod +x /usr/local/bin/vfio-bind.sh\n</code></pre> <p>Create the <code>systemd</code> service at <code>/etc/systemd/system/vfio-bind.service</code>.</p> <pre><code>[Unit]\nDescription=Bind GPUs to vfio-pci\nBefore=basic.target\nAfter=systemd-modules-load.service\nDefaultDependencies=no\n\n[Service]\nType=oneshot\nExecStart=/usr/local/bin/vfio-bind.sh\n\n[Install]\nWantedBy=basic.target\n</code></pre> <p>\ud83d\udd0d <code>DefaultDependencies=no</code> ensures it runs early, and <code>basic.target</code> is reached before most services or drivers load.</p> <p>Enable and rebuild initramfs (optional but recommended).</p> <pre><code>sudo systemctl enable vfio-bind.service\n</code></pre> <p>If you're not using <code>vfio-pci.ids</code> in your GRUB anymore (good!), you don\u2019t have to regenerate <code>initramfs</code>, but if you're still using any early-loading module configs, you might:</p> <pre><code>sudo update-initramfs -u\n</code></pre> <p>Reboot and confirm. After rebooting, confirm your devices are bound:</p> <pre><code>lspci -nnk | grep -A 3 -E 'VGA|Audio'\n</code></pre> <p>Look for your passthrough GPUs showing <code>Kernel driver in use: vfio-pci</code>.</p>"},{"location":"manual/#how-to-reject-dhcp-service-using-networkmanager","title":"How to Reject DHCP Service using <code>NetworkManager</code>","text":"<p>Create and edit <code>/etc/NetworkManager/dispatcher.d/10-block-bad-dhcp</code> to reject secondary DHCP service on a Linux that uses <code>NetworkManager</code>. Set the <code>eno1</code> argument according to the available adapter name.</p> <pre><code>#!/bin/bash\n\nIFACE=\"$1\"\nSTATUS=\"$2\"\n\nlogger \"NetworkManager: Triggered on $IFACE with status $STATUS\"\n\nif [ \"$IFACE\" = \"eno1\" ] &amp;&amp; [[ \"$STATUS\" == \"up\" || \"$STATUS\" == \"dhcp4-change\" ]]; then\n    IP=$(ip -4 addr show \"$IFACE\" | awk '/ inet / {print $2}' | cut -d/ -f1)\n    if [[ \"$IP\" == 192.168.* ]]; then\n        logger \"NetworkManager: Blocking DHCP lease from $IP on $IFACE\"\n        ip addr flush dev \"$IFACE\"\n        nmcli device disconnect \"$IFACE\"\n        sleep 2\n        nmcli device connect \"$IFACE\"\n    else\n        logger \"NetworkManager: Accepted $IP on $IFACE\"\n    fi\nfi\n\nexit 0\n</code></pre>"},{"location":"manual/#how-to-develop-the-hardcode-project","title":"How to develop the hardcode project","text":"<pre><code>git clone git@github.com:couper64/hardcode.git\ncd hardcode\n</code></pre> If the <code>hardcode</code> environment doesn't exist.If the <code>hardcode</code> environment does exist. <p>conda create -yn hardcode python=3 conda activate hardcode pip install -r requirements.txt</p> <p>conda activate hardcode</p> <p>Finally, after the environment is set and Python packages are installed for the local development. To run the <code>public</code> documentation.</p> <pre><code>mkdocs serve -f public/mkdocs.yml\n</code></pre> <p>And, to run the <code>private</code> documentation.</p> <pre><code>mkdocs serve -f private/mkdocs.yml\n</code></pre> <p>From this point on, the changes should immediately update every time the changes are saved.</p> <p>Note</p> <p>For completeness sake, below is the command to build the static website, but it isn't needed in our use case.</p> <pre><code>mkdocs build -f public/mkdocs.yml\nmkdocs build -f private/mkdocs.yml\n</code></pre>"},{"location":"manual/#how-to-resize-kvm-virtual-disk-size","title":"How to resize KVM virtual disk size","text":"<p>Resize the virtual disk size.</p> <pre><code>sudo qemu-img resize /data/kvm/&lt;vm_name&gt; +10G\n</code></pre> <p>Check if the virtual disk has been resized.</p> <pre><code>sudo qemu-img info /data/kvm/&lt;vm_name&gt;\n</code></pre> <p>This gives the path to the *.qcow2 file which is used as an argument to the resizing command.</p> <pre><code>sudo virsh domblklist &lt;vm_name&gt;\n</code></pre> <p>Make sure that there are no snapshots otherwise resizing won't work.</p> <pre><code>sudo virsh snapshot-list &lt;vm_name&gt;\n</code></pre> <p>Remove them using this command.</p> <pre><code>sudo virsh snapshot-delete &lt;vm_name&gt; &lt;snapshot_name&gt;\n</code></pre> <p>Instructions are based on this guide.</p>"},{"location":"manual/#how-to-set-default-text-editor","title":"How to set default text editor","text":"<p>Either just in a TTY, shell, or <code>.bashrc</code> [1].</p> <pre><code>export EDITOR=nano\n</code></pre>"},{"location":"manual/#how-to-enable-tpm-on-kvm","title":"How to enable TPM on KVM","text":"<pre><code>sudo pacman -S swtpm\n</code></pre> <p>Then in <code>virt-manager</code> [1, 2]:</p> <ol> <li>Allow customization before installation by checking the box. You can also configure the VM network. For this guide I have used a bridged network.</li> <li>On the overview windows, select add hardware.</li> <li>Add TPM 2.0 and make the settings as shown. Then click Finish to apply the changes.<ol> <li>Model: TIS</li> <li>Backend: Emulated device</li> <li>Version: 2.0</li> </ol> </li> <li>Just before you begin the installation, remember to change Firmware. Apply the changes and begin the installation.<ol> <li>Firmware: *_secboot.fd</li> </ol> </li> </ol>"},{"location":"manual/#how-to-install-surf-on-arch-linux","title":"How to install surf on Arch Linux","text":"<p>Install dependencies [1, 2].</p> <pre><code>sudo pacman -S gcr webkit2gtk-4.1\ngit clone git://git.suckless.org/surf ~/.local/src/surf\n</code></pre> <p>Use the following to open a webpage.</p> <pre><code>surf http://your-url\n</code></pre> <p>During operation, use <code>ctrl-g</code> to enter a new URL [1]. An interesting documentation could be found here at [1] as well.</p>"},{"location":"manual/#how-to-install-and-use-rclone","title":"How to Install and Use <code>rclone</code>","text":"<p>To install <code>rclone</code>, use the command <code>sudo pacman --sync rclone</code> on Arch.</p> <p>To mount a Google Drive remote with rclone, use the command <code>rclone mount remote_name: /path/to/mountpoint</code> replacing <code>remote_name</code> with your configured remote and <code>/path/to/mountpoint</code> with the local folder.</p>"},{"location":"manual/#appendix-a","title":"Appendix A","text":"<p>To hide the unmounted volumes, the setting is located at <code>Settings/Ubuntu Desktop/Dock/Configure Dock Behavior/Include Unmounted Volumes</code>.</p> <p>Command to recursively delete files.</p> <pre><code>find . -type f -name '*.o' -exec rm {} +\n</code></pre> <p>Command to recusrively clone a repository.</p> <pre><code>git clone --recurse-submodules git://github.com/foo/bar.git\n</code></pre> <p>Command to kill Ngrok process.</p> <pre><code>kill -9 \"$(pgrep ngrok)\"\n</code></pre> <p>Commands to run Ngrok in the background.</p> <pre><code>clear ; ngrok http http://localhost:8080 &gt; /dev/null &amp;\nclear ; export WEBHOOK_URL=\"$(curl http://localhost:4040/api/tunnels | jq \".tunnels[0].public_url\")\"\nclear ; echo $WEBHOOK_URL\n</code></pre> <p>Commands to install and setup Ngrok. First, sign up (in) and retrieve the authorisation token.</p> <pre><code>snap install ngrok\nngrok config add-authtoken &lt;token&gt;\n</code></pre> <p>Another installation command, because when I installed ngrok through snap, it couldn't start a service, but when installed through apt, it worked.</p> <pre><code>curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/ngrok.gpg &amp;&amp; \\\n  echo \"deb [signed-by=/etc/apt/keyrings/ngrok.gpg] https://ngrok-agent.s3.amazonaws.com buster main\" | \\\n  sudo tee /etc/apt/sources.list.d/ngrok.list &amp;&amp; \\\n  sudo apt update &amp;&amp; sudo apt install ngrok\nsudo ngrok service install --config /path/to/config.yml\nsudo ngrok service start\n</code></pre> <p>Although, all the messages were indicating \"ok\", it didn't work for me. Here is the config file.</p> <pre><code>authtoken: &lt;your-auth-token&gt;\ntunnels:\n    default:\n        proto: http\n        addr: 8080\n</code></pre>"},{"location":"manual/#apendix-b","title":"Apendix B","text":""},{"location":"manual/#how-to-develop-the-hardcode-project_1","title":"How to develop the hardcode project","text":"<pre><code>git clone git@github.com:couper64/hardcode.git\ncd hardcode\n</code></pre> If the <code>hardcode</code> environment doesn't exist.If the <code>hardcode</code> environment does exist. <p>conda create -yn hardcode python=3 conda activate hardcode pip install -r requirements.txt</p> <p>conda activate hardcode</p> <p>Finally, after the environment is set and Python packages are installed for the local development. To run the <code>public</code> documentation.</p> <pre><code>mkdocs serve -f public/mkdocs.yml\n</code></pre> <p>And, to run the <code>private</code> documentation.</p> <pre><code>mkdocs serve -f private/mkdocs.yml\n</code></pre> <p>From this point on, the changes should immediately update every time the changes are saved.</p> <p>Note</p> <p>For completeness sake, below is the command to build the static website, but it isn't needed in our use case.</p> <pre><code>mkdocs build -f public/mkdocs.yml\nmkdocs build -f private/mkdocs.yml\n</code></pre>"},{"location":"manual/#how-to-resize-kvm-virtual-disk-size_1","title":"How to resize KVM virtual disk size","text":"<p>Resize the virtual disk size.</p> <pre><code>sudo qemu-img resize /data/kvm/&lt;vm_name&gt; +10G\n</code></pre> <p>Check if the virtual disk has been resized.</p> <pre><code>sudo qemu-img info /data/kvm/&lt;vm_name&gt;\n</code></pre> <p>This gives the path to the *.qcow2 file which is used as an argument to the resizing command.</p> <pre><code>sudo virsh domblklist &lt;vm_name&gt;\n</code></pre> <p>Make sure that there are no snapshots otherwise resizing won't work.</p> <pre><code>sudo virsh snapshot-list &lt;vm_name&gt;\n</code></pre> <p>Remove them using this command.</p> <pre><code>sudo virsh snapshot-delete &lt;vm_name&gt; &lt;snapshot_name&gt;\n</code></pre> <p>Instructions are based on this guide.</p>"},{"location":"manual/#how-to-set-default-text-editor_1","title":"How to set default text editor","text":"<p>Either just in a TTY, shell, or <code>.bashrc</code> [1].</p> <pre><code>export EDITOR=nano\n</code></pre>"},{"location":"manual/#how-to-enable-tpm-on-kvm_1","title":"How to enable TPM on KVM","text":"<pre><code>sudo pacman -S swtpm\n</code></pre> <p>Then in <code>virt-manager</code> [1, 2]:</p> <ol> <li>Allow customization before installation by checking the box. You can also configure the VM network. For this guide I have used a bridged network.</li> <li>On the overview windows, select add hardware.</li> <li>Add TPM 2.0 and make the settings as shown. Then click Finish to apply the changes.<ol> <li>Model: TIS</li> <li>Backend: Emulated device</li> <li>Version: 2.0</li> </ol> </li> <li>Just before you begin the installation, remember to change Firmware. Apply the changes and begin the installation.<ol> <li>Firmware: *_secboot.fd</li> </ol> </li> </ol>"},{"location":"manual/#how-to-install-surf-on-arch-linux_1","title":"How to install surf on Arch Linux","text":"<p>Install dependencies [1, 2].</p> <pre><code>sudo pacman -S gcr webkit2gtk-4.1\ngit clone git://git.suckless.org/surf ~/.local/src/surf\n</code></pre> <p>Use the following to open a webpage.</p> <pre><code>surf http://your-url\n</code></pre> <p>During operation, use <code>ctrl-g</code> to enter a new URL [1]. An interesting documentation could be found here at [1] as well.</p>"},{"location":"manual/#how-to-install-and-use-rclone_1","title":"How to Install and Use <code>rclone</code>","text":"<p>To install <code>rclone</code>, use the command <code>sudo pacman --sync rclone</code> on Arch.</p> <p>To mount a Google Drive remote with rclone, use the command <code>rclone mount remote_name: /path/to/mountpoint</code> replacing <code>remote_name</code> with your configured remote and <code>/path/to/mountpoint</code> with the local folder.</p>"},{"location":"manual/#appendix-a_1","title":"Appendix A","text":"<p>To hide the unmounted volumes, the setting is located at <code>Settings/Ubuntu Desktop/Dock/Configure Dock Behavior/Include Unmounted Volumes</code>.</p> <p>Command to recursively delete files.</p> <pre><code>find . -type f -name '*.o' -exec rm {} +\n</code></pre> <p>Command to recusrively clone a repository.</p> <pre><code>git clone --recurse-submodules git://github.com/foo/bar.git\n</code></pre> <p>Command to kill Ngrok process.</p> <pre><code>kill -9 \"$(pgrep ngrok)\"\n</code></pre> <p>Commands to run Ngrok in the background.</p> <pre><code>clear ; ngrok http http://localhost:8080 &gt; /dev/null &amp;\nclear ; export WEBHOOK_URL=\"$(curl http://localhost:4040/api/tunnels | jq \".tunnels[0].public_url\")\"\nclear ; echo $WEBHOOK_URL\n</code></pre> <p>Commands to install and setup Ngrok. First, sign up (in) and retrieve the authorisation token.</p> <pre><code>snap install ngrok\nngrok config add-authtoken &lt;token&gt;\n</code></pre> <p>Another installation command, because when I installed ngrok through snap, it couldn't start a service, but when installed through apt, it worked.</p> <pre><code>curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/ngrok.gpg &amp;&amp; \\\n  echo \"deb [signed-by=/etc/apt/keyrings/ngrok.gpg] https://ngrok-agent.s3.amazonaws.com buster main\" | \\\n  sudo tee /etc/apt/sources.list.d/ngrok.list &amp;&amp; \\\n  sudo apt update &amp;&amp; sudo apt install ngrok\nsudo ngrok service install --config /path/to/config.yml\nsudo ngrok service start\n</code></pre> <p>Although, all the messages were indicating \"ok\", it didn't work for me. Here is the config file.</p> <pre><code>authtoken: &lt;your-auth-token&gt;\ntunnels:\n    default:\n        proto: http\n        addr: 8080\n</code></pre>"},{"location":"portfolio/","title":"\ud83d\udda5\ufe0f Portfolio","text":""},{"location":"portfolio/#unity-ps4-racing-game-space-cruiser","title":"\ud83c\udfae Unity PS4 Racing Game: Space Cruiser","text":"<p>Overview: Space Cruiser is a futuristic racing game developed for the Brighton:Develop conference. The game was designed to showcase innovative gameplay mechanics and high-quality visuals, taking full advantage of Unity\u2019s High Definition Render Pipeline (HDRP) and PlayStation SDK.</p> <p>Role &amp; Contributions: - Developed core gameplay mechanics, including vehicle controls and player interactions. - Implemented realistic levitation physics using a PID controller, a technique widely used in robotics to ensure smooth and responsive movement. - Designed and fine-tuned Sixaxis motion controls for PlayStation 4, enhancing player immersion. - Assisted in game design and contributed to environmental animations, ensuring cohesive world-building.</p> <p>Technologies &amp; Tools: - Unity HDRP \u2013 for enhanced graphical fidelity. - PlayStation SDK \u2013 for platform-specific development and Sixaxis integration. - C# and Unity Physics Engine \u2013 to handle smooth vehicle movement and interactions.  </p>"},{"location":"portfolio/#vulkan-c-game-engine-gtec","title":"\ud83d\udee0 Vulkan C++ Game Engine: GTEC","text":"<p>Overview: GTEC is a custom-built game engine written in C++ with Vulkan rendering, developed as part of my final-year university project. The engine serves as a foundation for understanding low-level graphics programming and efficient rendering techniques.</p> <p>Role &amp; Contributions: - Designed and implemented the core engine architecture, focusing on modularity and scalability. - Developed a Vulkan-based rendering pipeline, transitioning from OpenGL to explore modern, high-performance graphics. - Gained a deep understanding of memory management, GPU synchronisation, and multi-threading in rendering. - Identified and addressed key challenges in engine design, informing future projects and optimisations.</p> <p>Technologies &amp; Tools: - C++ \u2013 for performance-critical engine development. - Vulkan API \u2013 for low-level, high-performance rendering. - GLFW \u2013 for cross-platform window and input handling.  </p>"},{"location":"portfolio/#hololens-unity-ar-game-target","title":"\ud83d\udd37 Hololens Unity AR Game: Target","text":"<p>Overview: Target is an experimental Augmented Reality (AR) game designed for Microsoft Hololens, developed as part of my postgraduate research. The project explored the challenges of spatial computing, gesture-based interaction, and object recognition within AR environments.</p> <p>Role &amp; Contributions: - Developed gameplay mechanics optimised for Hololens, ensuring smooth gesture and voice-based interactions. - Implemented real-time object recognition using YOLO (You Only Look Once) within Unity\u2019s Barracuda inference engine. - Overcame technical challenges, such as integrating Azure voice recognition with MRTK, where library conflicts affected microphone accessibility. - Experimented with Unity\u2019s Universal Windows Platform (UWP) for deploying applications on mixed-reality devices.</p> <p>Technologies &amp; Tools: - Unity MRTK (Mixed Reality Toolkit) \u2013 to facilitate AR interactions. - YOLO &amp; Barracuda AI Inference Engine \u2013 for real-time object recognition. - Azure Speech Recognition \u2013 for voice command integration. - C# and UWP \u2013 for optimising performance on Hololens hardware.  </p>"}]}